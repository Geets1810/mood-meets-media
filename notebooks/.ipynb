{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packaging\n",
      "  Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: packaging\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.4\n",
      "    Uninstalling packaging-20.4:\n",
      "      Successfully uninstalled packaging-20.4\n",
      "Successfully installed packaging-24.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: requests in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (2020.10.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: requests in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\vanathi\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --upgrade --use-feature=2020-resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packaging version: 24.2\n"
     ]
    }
   ],
   "source": [
    "import packaging\n",
    "print(\"Packaging version:\", packaging.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7831bb8d08b478ca9014409e65469c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='config.json'), FloatProgress(value=0.0, max=1005.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vanathi\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vanathi\\.cache\\huggingface\\hub\\models--j-hartmann--emotion-english-distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d758c863614f1aa65842402bf8aa0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='pytorch_model.bin'), FloatProgress(value=0.0, max=328544361.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.utils' has no attribute 'parametrizations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-59964424d138>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text-classification\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"j-hartmann/emotion-english-distilroberta-base\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m         \u001b[0mmodel_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m         framework, model = infer_framework_load_model(\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[0mmodel_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"eval\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             return model_class.from_pretrained(\n\u001b[0m\u001b[0;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4223\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4224\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4225\u001b[1;33m             \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4226\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4227\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[0;32m   4402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4403\u001b[0m         \u001b[0moriginal_loaded_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4404\u001b[1;33m         \u001b[0mloaded_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_fix_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4403\u001b[0m         \u001b[0moriginal_loaded_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4404\u001b[1;33m         \u001b[0mloaded_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_fix_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36m_fix_key\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m   4389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4390\u001b[0m             \u001b[1;31m# to avoid logging parametrized weight norm renaming\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4391\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparametrizations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"weight_norm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4392\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"weight_g\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4393\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weight_g\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"parametrizations.weight.original0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn.utils' has no attribute 'parametrizations'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting typing_extensions\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "Successfully installed typing-extensions-4.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade typing_extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17a70795d854a389d4c5a8dd36e31aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='tokenizer_config.json'), FloatProgress(value=0.0, max=294.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vanathi\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vanathi\\.cache\\huggingface\\hub\\models--j-hartmann--emotion-english-distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf5fed3cb0b450898b88f8a44e05800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='vocab.json'), FloatProgress(value=0.0, max=798293.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e94d3ea00143f3ba54c1033c27baf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='merges.txt'), FloatProgress(value=0.0, max=456356.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7642985f7ba46bfae1060dfec8c2b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='tokenizer.json'), FloatProgress(value=0.0, max=1356047.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce74c4f234ff4c5db831faafbf687bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='special_tokens_map.json'), FloatProgress(value=0.0, max=239.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'joy', 'score': 0.9543430805206299}]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", top_k=1)\n",
    "classifier(\"This movie was a delightful surprise!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Vanathi/mood-meets-media/data/external/netflix_titles.csv\", encoding=\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8809 entries, 0 to 8808\n",
      "Data columns (total 26 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   show_id       8809 non-null   object \n",
      " 1   type          8809 non-null   object \n",
      " 2   title         8809 non-null   object \n",
      " 3   director      6175 non-null   object \n",
      " 4   cast          7984 non-null   object \n",
      " 5   country       7978 non-null   object \n",
      " 6   date_added    8799 non-null   object \n",
      " 7   release_year  8809 non-null   int64  \n",
      " 8   rating        8805 non-null   object \n",
      " 9   duration      8806 non-null   object \n",
      " 10  listed_in     8809 non-null   object \n",
      " 11  description   8809 non-null   object \n",
      " 12  Unnamed: 12   0 non-null      float64\n",
      " 13  Unnamed: 13   0 non-null      float64\n",
      " 14  Unnamed: 14   0 non-null      float64\n",
      " 15  Unnamed: 15   0 non-null      float64\n",
      " 16  Unnamed: 16   0 non-null      float64\n",
      " 17  Unnamed: 17   0 non-null      float64\n",
      " 18  Unnamed: 18   0 non-null      float64\n",
      " 19  Unnamed: 19   0 non-null      float64\n",
      " 20  Unnamed: 20   0 non-null      float64\n",
      " 21  Unnamed: 21   0 non-null      float64\n",
      " 22  Unnamed: 22   0 non-null      float64\n",
      " 23  Unnamed: 23   0 non-null      float64\n",
      " 24  Unnamed: 24   0 non-null      float64\n",
      " 25  Unnamed: 25   0 non-null      float64\n",
      "dtypes: float64(14), int64(1), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# If not already loaded\n",
    "#df = pd.read_csv(\"C:/Users/Vanathi/mood-meets-media/data/external/netflix_titles.csv\", encoding=\"cp1252\")\n",
    "\n",
    "# Keep only needed columns\n",
    "df = df[[\"title\", \"type\", \"listed_in\", \"description\"]].dropna()\n",
    "\n",
    "# Define mood extraction function\n",
    "def classify_mood(text):\n",
    "    try:\n",
    "        result = classifier(text[:512])  # Hugging Face limit is 512 tokens\n",
    "        return result[0]['label']\n",
    "    except:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Apply mood classification\n",
    "df[\"mood_tag\"] = df[\"description\"].apply(classify_mood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'joy', 'score': 0.9734006524085999}, {'label': 'neutral', 'score': 0.01155413780361414}, {'label': 'surprise', 'score': 0.007368728052824736}, {'label': 'sadness', 'score': 0.00499831372871995}, {'label': 'disgust', 'score': 0.001218730234540999}, {'label': 'fear', 'score': 0.0008531378116458654}, {'label': 'anger', 'score': 0.0006063509499654174}]]\n"
     ]
    }
   ],
   "source": [
    "# Use top_k=None to get all emotions and scores\n",
    "full_classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", top_k=None)\n",
    "\n",
    "# Try on a sample\n",
    "sample = \"A heartwarming story of friendship and courage.\"\n",
    "scores = full_classifier(sample)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot counts of mood_tag (the top emotion assigned)\n",
    "sns.countplot(y=df['mood_tag'], order=df['mood_tag'].value_counts().index, palette=\"pastel\")\n",
    "plt.title(\"Distribution of Emotions in Netflix Descriptions\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Emotion\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Netflix metadata with mood tagging saved!\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={\"listed_in\": \"genre\", \"description\": \"tags\"})\n",
    "df.to_csv(\"C:/Users/Vanathi/mood-meets-media/data/processed/netflix_enriched_metadata.csv\", index=False)\n",
    "print(\"✅ Netflix metadata with mood tagging saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
